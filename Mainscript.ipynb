{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac808169-8328-4972-80f1-0aa6b67593f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['airplane', 'ambulance', 'apple', 'backpack', 'banana', 'bathtub', 'bear', 'bed', 'bee', 'bicycle', 'bird', 'book', 'bridge', 'bus', 'butterfly', 'cake', 'calculator', 'camera', 'car', 'cat', 'chair', 'clock', 'cow', 'dog', 'dolphin', 'donut', 'drums', 'duck', 'elephant', 'fence', 'fork', 'horse', 'house', 'rabbit', 'scissors', 'sheep', 'strawberry', 'table', 'telephone', 'truck'] \n",
      "\n",
      "source_path: C:\\Users\\USER\\befor_start_1404\\Recon_code\\Recon\\domainnet\\clipart \n",
      "target_path: C:\\Users\\USER\\befor_start_1404\\Recon_code\\Recon\\domainnet\\real \n",
      "\n",
      "Using device: cuda \n",
      "\n",
      "Source domain\n",
      "airplane : 0  table : 37  dolphin : 24  telephone : 38  truck : 39  table : 37  bed : 7  airplane : 0  bird : 10  fork : 30  strawberry : 36  table : 37  cake : 15  bed : 7  bed : 7  airplane : 0  bathtub : 5  truck : 39  clock : 21  ambulance : 1  horse : 31  house : 32  dolphin : 24  clock : 21  duck : 27  book : 11  donut : 25  clock : 21  telephone : 38  bear : 6  cat : 19  duck : 27  \n",
      "----------------------------------\n",
      "Target domain\n",
      "truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  elephant : 28  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  donut : 25  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  \n",
      "----------------------------------\n",
      "Test domain\n",
      "truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  bicycle : 9  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  rabbit : 33  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  book : 11  truck : 39  truck : 39  truck : 39  truck : 39  truck : 39  \n",
      "----------------------------------\n",
      "ARKG method settings loaded. Namespace(dataset='domainnet', main_folder='C:\\\\Users\\\\USER\\\\befor_start_1404\\\\Recon_code\\\\Recon', num_class=41, source_domain='clipart', target_domain='real', seed=42, allowed_hosts='DESKTOP-65IEAN0', image_size=224, batch_size=32, device='cuda', backbone='densenet121', latent_dimention=256, drop_p=0.1, out_features=128, dec0=64, dec1=128, dec2=256, dec3=512, dec4=1024, size_recimg=128, max_steps=1000, fc_units=512, T=1, input_Disc=64, num_epochs=1000, min_lr=1e-08, alpha=10.0, beta=0.75, start_point=150, Beta2=0.01, Beta1=0.1, rho=3.0, recon_loss_type='mse', lr_Ens=1e-05, lr_Ent=1e-05, lr_Dec=0.001, lr_Cls=0.0001, lr_Dis=0.001, lr_Fsh=1e-05)\n",
      "Random Seed:  42\n",
      "cuda is available: True\n",
      "Authorized host: DESKTOP-65IEAN0\n",
      "Running on authorized server. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13796\\841201676.py:23: DeprecationWarning: numpy.core is deprecated and has been renamed to numpy._core. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.__version__.\n",
      "  if hasattr(module, \"__version__\"):\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13796\\841201676.py:25: DeprecationWarning: numpy.core is deprecated and has been renamed to numpy._core. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.__version__.\n",
      "  f.write(f\"{name}=={module.__version__}\\n\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -th iteration of  4383\n",
      "1 -th iteration of  4383\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning on authorized server.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m config\u001b[38;5;241m=\u001b[39m ARKG\u001b[38;5;241m.\u001b[39mDemo()\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 61\u001b[0m loss_list \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtrain(args\u001b[38;5;241m.\u001b[39mnum_epochs)\n",
      "File \u001b[1;32m~\\befor_start_1404\\Recon_code\\Recon\\ARKG_Reyhane_Ghaffari\\ARKG.py:367\u001b[0m, in \u001b[0;36mDemo.train\u001b[1;34m(self, max_epoch)\u001b[0m\n\u001b[0;32m    365\u001b[0m   Dt_label,_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDis_net\u001b[38;5;241m.\u001b[39mforward(Rec_t_eval)\n\u001b[0;32m    366\u001b[0m   Prob_t\u001b[38;5;241m=\u001b[39m Dt_label\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m   score_com_[:,i]\u001b[38;5;241m=\u001b[39mProb_t \n\u001b[0;32m    368\u001b[0m   exp_delta_[:,i]\u001b[38;5;241m=\u001b[39m(Prob_t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1e-10\u001b[39m) \u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m Prob_t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1e-10\u001b[39m)\n\u001b[0;32m    370\u001b[0m Negat_exp_delta\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mexp_delta_)\n",
      "File \u001b[1;32m~\\.conda\\envs\\MyCondaEnv\\Lib\\site-packages\\torch\\fx\\traceback.py:66\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m             current_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_grad_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m current_level \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     63\u001b[0m             current_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_fn_seq_nr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m current_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_fn_seq_nr\u001b[39m\u001b[38;5;124m\"\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;129m@compatibility\u001b[39m(is_backward_compatible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_stack\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_preserve_node_meta:\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import argparse\n",
    "import numpy as np\n",
    "from setting import get_setting\n",
    "from dataload import get_dataset_paths\n",
    "from server_auth import check_server_auth\n",
    "from dataload import get_transforms, get_dataset_classes, get_dataset_paths\n",
    "from dataload import prepare_dataloaders\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import traceback\n",
    "import ARKG\n",
    "import sys\n",
    "\n",
    "with open(\"used_packages.txt\", \"w\") as f:\n",
    "    for name, module in sys.modules.items():\n",
    "        if hasattr(module, \"__version__\"):\n",
    "            try:\n",
    "                f.write(f\"{name}=={module.__version__}\\n\")\n",
    "            except Exception:\n",
    "                # Some modules have __version__ but may throw errors\n",
    "                pass\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "args = get_setting()\n",
    "if args.seed is None:\n",
    "    args.seed = random.randint(1, 10000)\n",
    "print(\"ARKG method settings loaded.\",args)\n",
    "print(\"Random Seed: \", args.seed)\n",
    "\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "# GPU/CPU flags\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "if torch.cuda.is_available() and args.device != \"cuda\":\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --device cuda\")\n",
    "\n",
    "if args.device == \"cuda\":\n",
    "    print(\"cuda is available:\", torch.cuda.is_available())\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"  \n",
    "    \n",
    "load_epoch= -1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    allowed = args.allowed_hosts.split(',') \n",
    "    check_server_auth(allowed)\n",
    "    print(\"Running on authorized server.\",\"\\n\")\n",
    "    config= ARKG.Demo().to(args.device)\n",
    "    loss_list = config.train(args.num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1c6f74-dff6-4d3d-a141-16e4497195ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    for dist in pkg_resources.working_set:\n",
    "        f.write(f\"{dist.key}=={dist.version}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6354f2-42c4-421b-9830-0e8eb97c6391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
